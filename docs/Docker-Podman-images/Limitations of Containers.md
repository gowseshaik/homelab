- `Lack of Self Healing` : No built-in mechanism to automatically re-create containers
- `High Availability Challenges`:  When server fails, entire application becomes unavailable, causing significant downtime
- `Scaling hurdles` :  Lacks automatic scaling
- `Load Balancing Challenges` : Doesn't directly handle load balancing
- `Storage Constraints` : Rely on the underlying host system's storage resources

| **Limitation**                                                     | **Why It Happens**                                                      | **Impact**                                    | **Common Bias / Assumption**          | **Solution / Best Practice**                                                         |
| ------------------------------------------------------------------ | ----------------------------------------------------------------------- | --------------------------------------------- | ------------------------------------- | ------------------------------------------------------------------------------------ |
| <span style="color:red">Limited OS-level isolation</span>          | Containers share host kernel                                            | Less secure than VMs                          | "Containers are like lightweight VMs" | Use rootless containers, user namespaces, SELinux/AppArmor                           |
| <span style="color:orange">Resource contention</span>              | Shared CPU/memory between containers                                    | One container can starve others               | "Kubernetes handles everything"       | Set CPU/memory limits/requests in pod specs                                          |
| <span style="color:red">Weak security boundaries</span>            | Linux namespaces/cgroups offer process-level, not full system isolation | Exploits can affect host or other containers  | "Containers are secure by default"    | Enable seccomp, AppArmor, non-root users, and readonly filesystems                   |
| <span style="color:purple">No persistence by default</span>        | Containers are ephemeral/stateless                                      | Data loss on restarts or removal              | "Containers just work out of the box" | Mount persistent volumes using PVCs or bind mounts                                   |
| <span style="color:teal">Networking is complex</span>              | Virtual networks and overlays are used                                  | Harder to debug and manage                    | "Networking is auto-managed"          | Use well-documented CNI plugins; visualize with tools like `weave`, `cilium`, `lens` |
| <span style="color:gray">Logging is ephemeral</span>               | Logs disappear when containers stop                                     | Lost logs = lost visibility                   | "Container logs are always available" | Use centralized logging (EFK, Loki, Fluentbit)                                       |
| <span style="color:brown">Poor for stateful workloads</span>       | Stateless is default; state requires extra setup                        | Data consistency problems, scaling challenges | "Just deploy databases in containers" | Use StatefulSets and persistent volumes; or external DBaaS                           |
| <span style="color:darkblue">Cold start issues</span>              | Images must be pulled and initialized                                   | Higher latency on scale-up                    | "Containers start instantly"          | Pre-pull images, reduce size, keep base image in memory                              |
| <span style="color:crimson">Vulnerable images</span>               | Base images may contain CVEs or malware                                 | Security risk, compliance issues              | "Using Alpine means it's secure"      | Scan with Trivy, Grype; use trusted sources                                          |
| <span style="color:darkgreen">Image bloat / dependency hell</span> | Unnecessary libs included in images                                     | Larger attack surface, slower builds          | "Dockerfile is enough"                | Use multi-stage builds; prefer `distroless`, minimal images                          |

| **Misunderstood**                                                                          | **Why It's Misleading or Dangerous**                   | **Reality Check / Correction**                          | **Fix It**                                                              |
| ------------------------------------------------------------------------------------------ | ------------------------------------------------------ | ------------------------------------------------------- | ----------------------------------------------------------------------- |
| <span style="color:orangered">Containers are like lightweight VMs</span>                   | Containers share kernel, unlike isolated VMs           | Containers are process-isolated, not fully OS-isolated  | Use user namespaces, seccomp, rootless mode                             |
| <span style="color:darkorange">Kubernetes handles everything, I don’t need to worry</span> | K8s doesn't enforce security, resource limits, logging | You must configure policies, limits, and monitoring     | Set resource requests/limits, apply PodSecurityPolicies, enable logging |
| <span style="color:goldenrod">Using containers ensures scalability</span>                  | Badly designed apps won’t scale                        | Stateless, loosely coupled design is required           | Build stateless microservices, externalize state, use health checks     |
| <span style="color:crimson">All container images are safe to use</span>                    | Public images may have CVEs or malware                 | Always scan and verify base images                      | Use trusted registries, scan with Trivy/Grype, sign images              |
| <span style="color:firebrick">Once it's containerized, it’s production-ready</span>        | Dev/test success doesn’t mean it's hardened            | Security, monitoring, and compliance need to be applied | Use image policies, observability stack, vulnerability scanners         |
| <span style="color:darkslateblue">Dockerfile is enough to define the app</span>            | No lifecycle, logging, recovery, scaling in Dockerfile | Use Helm charts or K8s manifests                        | Define full app spec using Helm/Operators                               |
| <span style="color:teal">One container = one service = done</span>                         | Ignores lifecycle, health, state, updates              | Requires orchestration, health checks, rollbacks        | Use readiness/liveness probes, rolling deployments, sidecars if needed  |
| <span style="color:gray">Container logs are always accessible</span>                       | Logs vanish on restart unless redirected               | Use centralized logging stack                           | Deploy EFK/Loki, use persistent log volumes or logging agents           |
| <span style="color:brown">Containers are secure by default</span>                          | Defaults allow root, no seccomp, no network rules      | Security hardening must be done explicitly              | Apply securityContext, AppArmor, rootless containers                    |
| <span style="color:green">Minimal base image = safe image</span>                           | Even Alpine or scratch can have CVEs                   | Minimal != secure, must still be scanned                | Use distroless + image scanners regularly                               |
